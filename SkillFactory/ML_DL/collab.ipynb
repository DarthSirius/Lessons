{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m data_all \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/combined_data_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCust_Id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     data_all\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:889\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1034\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1088\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1163\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1380\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1336\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr_or_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr_or_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m   1382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_all = []\n",
    "for i in range(4):\n",
    "    data = pd.read_csv('data/combined_data_' + str(i+1)+'.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "    data_all.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (100498277, 2)\n",
      "-Dataset examples-\n",
      "           Cust_Id  Rating\n",
      "0               1:     NaN\n",
      "5000000    2560324     4.0\n",
      "10000000   2271935     2.0\n",
      "15000000   1921803     2.0\n",
      "20000000   1933327     3.0\n",
      "25000000   1465002     3.0\n",
      "30000000    961023     4.0\n",
      "35000000   1372532     5.0\n",
      "40000000    854274     5.0\n",
      "45000000    116334     3.0\n",
      "50000000    768483     3.0\n",
      "55000000   1331144     5.0\n",
      "60000000   1609324     2.0\n",
      "65000000   1699240     3.0\n",
      "70000000   1776418     4.0\n",
      "75000000   1643826     5.0\n",
      "80000000    932047     4.0\n",
      "85000000   2292868     4.0\n",
      "90000000    932191     4.0\n",
      "95000000   1815101     3.0\n",
      "100000000   872339     4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df.index = np.arange(0,len(df))\n",
    "print('Full dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "df_nan = df_nan[df_nan['Rating'] == True]\n",
    "df_nan = df_nan.reset_index()\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,np.abs(i-j-1)), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "\n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Dataset examples-\n",
      "          Cust_Id  Rating  Movie_Id\n",
      "51388783  1560508     4.0      9298\n",
      "17486820  1823426     5.0      3355\n",
      "69922382  1322665     3.0     12672\n"
     ]
    }
   ],
   "source": [
    "df = df[pd.notnull(df['Rating'])]\n",
    "\n",
    "df['Movie_Id'] = movie_np.astype(int)\n",
    "df['Cust_Id'] = df['Cust_Id'].astype(int)\n",
    "print('-Dataset examples-')\n",
    "print(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/data_prep1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('data/data_prep1.csv', sep=';', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/data_prep1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17770"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Movie_Id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480189"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cust_Id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_sample = df.Cust_Id.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sample = df.Movie_Id.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(df[df.Cust_Id.isin(cust_sample) &\n",
    "                              df.Movie_Id.isin(movie_sample)][['Cust_Id', 'Movie_Id', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    " \n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1e68763a560>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(trainingSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = trainingSet.build_anti_testset()\n",
    "predictions = knn.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('data/movie_titles.csv', encoding = \"ISO-8859-1\", \n",
    "                     header = None, \n",
    "                     on_bad_lines='skip',\n",
    "                     names = ['Movie_Id', 'Year', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=2477414, iid=17, r_ui=3.586179789789014, est=4.59980242801443, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=2477414, iid=18, r_ui=3.586179789789014, est=4.724826118541935, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=2477414, iid=19, r_ui=3.586179789789014, est=4.700345235427843, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=2477414, iid=28, r_ui=3.586179789789014, est=4.875274580788756, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    " \n",
    "def get_top3_recommendations(predictions, topN = 3):\n",
    "     \n",
    "    top_recs = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_recs[uid].append((iid, est))\n",
    "     \n",
    "    for uid, user_ratings in top_recs.items():\n",
    "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        top_recs[uid] = user_ratings[:topN]\n",
    "     \n",
    "    return top_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_recommendations = get_top3_recommendations(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_recs(i):\n",
    "    for (a, b) in top3_recommendations[i]:\n",
    "        print(titles[titles.Movie_Id == a]['Name'].values[0], np.round(b,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 262149\n",
    "print_recs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band of Brothers 4.45\n",
      "Schindler's List 4.4\n",
      "Scarface: 20th Anniversary Edition 4.4\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(list(top3_recommendations.keys()))\n",
    "\n",
    "print_recs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Phantom of the Opera: Special Edition', 'American Beauty',\n",
       "       \"Singin' in the Rain\",\n",
       "       'Lord of the Rings: The Fellowship of the Ring', 'Braveheart',\n",
       "       'The King and I', 'Star Wars: Episode V: The Empire Strikes Back',\n",
       "       'The Terminator', 'Lawrence of Arabia',\n",
       "       'Lord of the Rings: The Two Towers: Extended Edition',\n",
       "       'The Lord of the Rings: The Fellowship of the Ring: Extended Edition',\n",
       "       'Minority Report', 'RoboCop', 'Terminator 2: Extreme Edition',\n",
       "       'Caddyshack', 'Star Wars: Episode VI: Return of the Jedi',\n",
       "       'Twister', 'Star Trek II: The Wrath of Khan',\n",
       "       'Raiders of the Lost Ark', 'Forrest Gump',\n",
       "       'Lord of the Rings: The Two Towers', 'Contact', 'Spider-Man 2',\n",
       "       'The Godfather', \"National Lampoon's Animal House\", 'Men in Black',\n",
       "       'Bicentennial Man', 'Blazing Saddles', 'Gladiator', 'Cast Away',\n",
       "       'Lord of the Rings: The Return of the King', 'Jurassic Park',\n",
       "       'The Shawshank Redemption: Special Edition', 'Shrek (Full-screen)',\n",
       "       'The Matrix', 'Beetlejuice', 'Dead Poets Society',\n",
       "       'Lord of the Rings: The Return of the King: Extended Edition',\n",
       "       'The Green Mile', 'Unforgiven', 'Highlander', 'Titanic',\n",
       "       'Indiana Jones and the Last Crusade', 'Saving Private Ryan',\n",
       "       'E.T. the Extra-Terrestrial: The 20th Anniversary (Rerelease)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films = data.df[(data.df.Cust_Id == i) & (data.df.Rating == 5)]['Movie_Id'].values\n",
    "titles[titles.Movie_Id.isin(films)]['Name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 9.7.1\n",
    "\n",
    "Укажите индекс непросмотренного пользователем №2 фильма, который имеет наибольшую оценку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_matrix = np.array(((1,5,0,5,4), (5,4,4,3,2), (0,4,0,0,5), (4,4,1,4,0), (0,4,3,5,0), (2,4,3,5,3)))\n",
    "user_movie_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg  \n",
    "U, s, V = linalg.svd(user_movie_matrix,full_matrices=False)\n",
    "M=U @ np.diag(s) @ V # ок, работает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_2 = U[2:, :]\n",
    "V_2 = V[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2 = user_movie_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2_reduced = user_2 @ V_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2_predicted = user_2_reduced @ V_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.19719556, 4.22057993, 2.91894245, 4.851947  , 1.05421441])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_2_predicted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 9.7.2\n",
    "\n",
    "А теперь давайте проверим наше SVD разложение на новом пользователе. Выведите индекс непросмотренного новым пользователем фильма, который имеет наибольшую оценку. При этом новый пользователь что-то успел посмотреть: new_user = np.array((0, 0, 3, 4, 0))\n",
    "Обратите внивание: SVD-разложение проводите без нового пользователя! В этот раз используйте 3 компоненты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = np.array((0, 0, 3, 4, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_new_reduced = new_user @ V_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.88933495,  1.46416086,  1.72840648,  2.3739358 , -0.58706807])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_new_predicted = user_new_reduced @ V_2\n",
    "user_new_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import surprise\n",
    "import apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\Ustenko-S/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "data = surprise.Dataset.load_builtin(\"ml-100k\")\n",
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = trainingSet.build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 9.10.1\n",
    "\n",
    "Найдите количество пользователей в trainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet.n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet.n_items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
