Дипломный проект

# Модель прогнозирования стоимости жилья для агентства недвижимости


## Задача
Разработать модель, которая позволила бы агентству недвижимости обойти конкурентов по скорости и качеству совершения сделок

1. Провести разведывательный анализ и очистку исходных данных. Отыскать закономерности, самостоятельно расшифровать все сокращения, найти синонимы в данных, обработать пропуски и удалить выбросы.
2. Выделить наиболее значимые факторы, влияющие на стоимость недвижимости.
3. Построить модель для прогнозирования стоимости недвижимости.
4. Разработать небольшой веб-сервис, на вход которому поступают данные о некоторой выставленной на продажу недвижимости, а сервис прогнозирует его стоимость.
## Данные

data/data.csv

Описание данных:

➔ 'status' — статус продажи;
➔ 'private pool' и 'PrivatePool' — наличие собственного бассейна;
➔ 'propertyType' — тип объекта недвижимости;
➔ 'street' — адрес объекта;
➔ 'baths' — количество ванных комнат;
➔ 'homeFacts' — сведения о строительстве объекта (содержит несколько типов сведений, влияющих на оценку объекта);
➔ 'fireplace' — наличие камина;
➔ 'city' — город;
➔ 'schools' — сведения о школах в районе;
➔ 'sqft' — площадь в футах;
➔ 'zipcode' — почтовый индекс;
➔ 'beds' — количество спален;
➔ 'state' — штат;
➔ 'stories' — количество этажей;
➔ 'mls-id' и 'MlsId' — идентификатор MLS (Multiple Listing Service, система мультилистинга);
➔ 'target' — цена объекта недвижимости (целевой признак, который необходимо спрогнозировать).

## Структура файлов проекта


EDA.ipynb - ноутбук содержайщий операции по подготовке и очистке датасета

ML.ipynb - выбор модели, подбор гиперпараметров, обучение и сериализация модели

web_app/app/server.py - серверная часть веб-приложения

web_app/app/client.py - клиентская часть веб-приложения

model.pkl - "законсервированная" ML-модель

## Этапы выполнения работ

BEDA.ipynb
1. Загрузка данных из csv-файла
2. Подготовка данных, в том числе распаковка свернутых признаков, кодировка бинарных признаков ручным и автоматическими методами
3. Очистка датасета, в том числе удаление выбросов, замена значений, поиск ключевых фраз для кодировки 
3. Оценка распределения признаков средствами визуализации, логарифмирование экспоненциальных распределений
4. Выгрузка подготовленных данных в csv

ML.ipynb
1. Загрузка данных
2. Разбивка выборки на тренировочный, тестовый и валидационный наборы
3. Оценка наивным методом (средним значением)
4. Оценка Линейной регрессии
5. Построение матрицы корреляций
6. Нормализация и сериализация признаков
7. Обучение регрессии на полиномах
8. Дерево решений. Подбор оптимальной глубины дерева
9. Применение ансамблевых методов. Случайный лес
10. Градиентный бустинг
11. Отбор признаков для ГБ
12. Подбор оптимальных гиперпараметров
13. Обучение модели
14. Сериализация модели
15. Подбор тестовых данных для веб-сервиса

Веб-сервис
1. Подготовка серверной части
2. Подготовка клиентской части

## Веб-сервис

Для использования обученной модели разработан веб-сервис на Flask. Сервис "слушает" порт 5000 на локальном хосте и обрабатывает POST-запросы по эндпоинту /predict.

Пробные данные готовятся в ноутбуке в виде строки массива тестового набора данных.
Пробные данные заносятся в виде списка длиной 33 в файле клиентской части (client.py) в переменную json.

Порядок запуска приложения:
1. Запускаем серверную часть.
2. В отдельном терминале запускаем клиента.

## Выводы

Датасет содержит сложно структурированные данные, требующие большого объема ручной кодировки, создания новых признаков и очистки. В датасете не обнаружено явно выраженных корреляций признаков с целевой переменной.
Были последовательно опробованы модели:
1. Линейная регрессия
2. Линейная регрессия на полиномиальных признаках 2й степени с L1, L2-регуляризацией
3. Дерево решений с оптимизацией глубины
4. Случайный лес деревьев решений
5. Градиентный бустинг
6. XGBoost
7. AdaBoost (Adaptive Boosting)
7. Стекинг с использованием регрессии и деревьев решений в качестве базовых моделей и случайного леса в качестве метамодели (в ноутубук не включен)

Последовательный перебор моделей показал, что наилучшие результаты дает модель градиентного бустинга. Удалось достичь качества предсказания в 28% MAPE и среднего абсолютного отклонения в 90000$.
Несмотря на тщательный подбор гиперпараметров, отбор признаков и отработку множества гипотез, повысить далее качество предсказания не удалось. Модель годится скорее для оперативной и приблизительной оценки стоимости недвижимости.

# Основные итоги работы
Создан прототип веб-сервиса для оперативной оценки стоимости недвижимости по заданным параметрам объекта.